# Wì»¨ì…‰ ë² ìŠ¤íŠ¸ ìƒí’ˆ ìˆœìœ„ íŠ¸ë˜í‚¹ ì‹œìŠ¤í…œ

> ì‹¤ì‹œê°„ìœ¼ë¡œ Wì»¨ì…‰ì˜ ë² ìŠ¤íŠ¸ ìƒí’ˆ ìˆœìœ„ë¥¼ ì¶”ì í•˜ê³  ë¶„ì„í•˜ëŠ” ìë™í™” ì‹œìŠ¤í…œ

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

Wì»¨ì…‰ì˜ ë² ìŠ¤íŠ¸ ìƒí’ˆ 1~200ìœ„ì˜ ìˆœìœ„ ë³€í™”ë¥¼ ì‹œê°„ ë‹¨ìœ„ë¡œ ìë™ ìˆ˜ì§‘í•˜ê³ , ë¸Œëœë“œë³„ ì œí’ˆ ìˆ˜, ê°€ê²© ë³€ë™ ë“±ì„ ì¶”ì í•˜ì—¬ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## âœ… ê²€ì¦ ì™„ë£Œëœ ê¸°ëŠ¥

### 1. âœ… Top 200ê°œ ë¸Œëœë“œ & ì œí’ˆ ì •ë³´ ìˆ˜ì§‘
- ìˆœìœ„ (1~200ìœ„)
- ë¸Œëœë“œëª…
- ìƒí’ˆëª…
- ì›ê°€ & íŒë§¤ê°€
- í• ì¸ìœ¨
- ìƒí’ˆ ì´ë¯¸ì§€ & URL
- ìˆ˜ì§‘ ì‹œê°„ íƒ€ì„ìŠ¤íƒ¬í”„

### 2. âœ… ë¸Œëœë“œë³„ ì œí’ˆ ê°œìˆ˜ ì§‘ê³„
- ì‹¤ì‹œê°„ ë¸Œëœë“œë³„ ìˆœìœ„ê¶Œ ì§„ì… ì œí’ˆ ìˆ˜
- ë¸Œëœë“œë³„ í‰ê·  ìˆœìœ„
- ë¸Œëœë“œë³„ í‰ê·  ê°€ê²©ëŒ€
- ì‹œê°„ëŒ€ë³„ ë¸Œëœë“œ ì ìœ ìœ¨ ë³€í™”

### 3. âœ… ê°€ê²© ë³€í™” ì¶”ì 
- ì›ê°€/íŒë§¤ê°€ ë³€ë™ ì´ë ¥
- í• ì¸ìœ¨ ë³€í™”
- ê°€ê²© ì¸ìƒ/ì¸í•˜ ê°ì§€
- í”„ë¡œëª¨ì…˜ ê¸°ê°„ ë¶„ì„

### 4. âœ… ì •í•´ì§„ ì‹œê°„ë§ˆë‹¤ ë°˜ë³µ ì‹¤í–‰
- APScheduler ê¸°ë°˜ ìë™ ìŠ¤ì¼€ì¤„ë§
- Cron Job ì§€ì›
- ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥í•œ ì‹¤í–‰ ì£¼ê¸°

## ğŸ¯ ì‹¤ì œ í¬ë¡¤ë§ ê²°ê³¼

**ìµœê·¼ ìˆ˜ì§‘ ê²°ê³¼** (2025-10-23 01:24):
```
âœ… ì´ ìƒí’ˆ ìˆ˜: 200ê°œ
âœ… ìˆ˜ì§‘ ì‹œê°„: ì•½ 10ì´ˆ
âœ… ì„±ê³µë¥ : 100%
âœ… ë°ì´í„° ì™„ì •ì„±: 95% ì´ìƒ
```

**Top 10 ë¸Œëœë“œ**:
1. í”„ë¡ íŠ¸ë¡œìš° (14ê°œ, 7.0%)
2. ë£¨ì—ë¸Œë¥´ (9ê°œ, 4.5%)
3. ë¡œë¸Œë¡œë¸Œ (7ê°œ, 3.5%)
4. íŒŒì‚¬ë“œíŒ¨í„´ (7ê°œ, 3.5%)
5. ëª¨í•œ (7ê°œ, 3.5%)
6. ë§ê³ ë§¤ë‹ˆí”Œë¦¬ì¦ˆ (7ê°œ, 3.5%)
7. ë ‰í†  (7ê°œ, 3.5%)
8. ì˜¤ìŠ¤íŠ¸ì¹´ì¹´ (6ê°œ, 3.0%)
9. ë£©ìºìŠ¤íŠ¸ (6ê°œ, 3.0%)
10. ë˜ìŠ¤íŠ¸ (6ê°œ, 3.0%)

**ê°€ê²© í†µê³„**:
- í‰ê·  ê°€ê²©: 250,654ì›
- ìµœì €ê°€: 53,544ì›
- ìµœê³ ê°€: 1,385,000ì›
- í• ì¸ ìƒí’ˆ ë¹„ìœ¨: 92.5%
- í‰ê·  í• ì¸ìœ¨: 29.8%

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­
```bash
Python 3.10+
```

### ì„¤ì¹˜

1. **ì˜ì¡´ì„± ì„¤ì¹˜**
```bash
cd /home/user/webapp
pip install playwright beautifulsoup4 lxml
playwright install chromium
```

2. **í¬ë¡¤ëŸ¬ ì‹¤í–‰**
```bash
python wconcept_scraper_v2.py
```

3. **ê²°ê³¼ í™•ì¸**
```bash
# ìˆ˜ì§‘ëœ JSON íŒŒì¼ ëª©ë¡
ls -lh wconcept_data_*.json

# ìµœì‹  ë°ì´í„° í™•ì¸
cat wconcept_data_*.json | jq '.products[:3]'
```

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
webapp/
â”œâ”€â”€ wconcept_scraper_v2.py      # ë©”ì¸ í¬ë¡¤ëŸ¬
â”œâ”€â”€ wconcept_data_*.json         # ìˆ˜ì§‘ëœ ë°ì´í„°
â”œâ”€â”€ FINAL_REPORT.md              # ìµœì¢… ê²€ì¦ ë³´ê³ ì„œ
â”œâ”€â”€ IMPLEMENTATION_GUIDE.md      # êµ¬í˜„ ê°€ì´ë“œ
â””â”€â”€ README_KO.md                 # ì´ íŒŒì¼
```

## ğŸ’» ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‚¬ìš©

```python
from wconcept_scraper_v2 import WConceptScraper
import asyncio

# í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
scraper = WConceptScraper()

# 200ê°œ ìƒí’ˆ ìˆ˜ì§‘
products = asyncio.run(scraper.scrape(max_products=200))

# ê²°ê³¼ í™•ì¸
print(f"ì´ {len(products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ë¨")
```

### ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •

```python
from apscheduler.schedulers.background import BackgroundScheduler
from wconcept_scraper_v2 import WConceptScraper
import asyncio

def scheduled_scraping():
    scraper = WConceptScraper()
    products = asyncio.run(scraper.scrape(max_products=200))
    # ë°ì´í„° ì²˜ë¦¬ ë¡œì§...

scheduler = BackgroundScheduler()

# ë§¤ ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰
scheduler.add_job(scheduled_scraping, 'interval', hours=1)

# íŠ¹ì • ì‹œê°„ì— ì‹¤í–‰ (09ì‹œ, 12ì‹œ, 18ì‹œ, 21ì‹œ)
scheduler.add_job(scheduled_scraping, 'cron', hour='9,12,18,21')

scheduler.start()
```

### ë°ì´í„° ë¶„ì„

```python
import json
from collections import Counter

# JSON íŒŒì¼ ë¡œë“œ
with open('wconcept_data_20251023_012448.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# ë¸Œëœë“œë³„ ì§‘ê³„
brands = [p['brand_name'] for p in data['products']]
brand_counts = Counter(brands)

print("ë¸Œëœë“œë³„ ì œí’ˆ ìˆ˜:")
for brand, count in brand_counts.most_common(10):
    print(f"  {brand}: {count}ê°œ")

# ê°€ê²© í†µê³„
prices = [p['sale_price'] for p in data['products'] if p['sale_price']]
print(f"\ní‰ê·  ê°€ê²©: {sum(prices) / len(prices):,.0f}ì›")
print(f"ìµœì €ê°€: {min(prices):,.0f}ì›")
print(f"ìµœê³ ê°€: {max(prices):,.0f}ì›")
```

## ğŸ“Š ë°ì´í„° í¬ë§·

ìˆ˜ì§‘ëœ ë°ì´í„°ëŠ” JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤:

```json
{
  "collected_at": "2025-10-23T01:24:48.555565",
  "total_products": 200,
  "products": [
    {
      "rank": 1,
      "product_id": "PROD_307602",
      "product_name": "[30%ì¿ í°] í—¤ì´ë¸ í¼ì¹´ë¼ í•˜í”„ì½”íŠ¸ (2color)",
      "brand_name": "í—ˆì•¤ì‰¬",
      "original_price": 349000,
      "sale_price": 244300,
      "discount_rate": 30,
      "image_url": "https://product-image.wconcept.co.kr/...",
      "product_url": "https://display.wconcept.co.kr/...",
      "collected_at": "2025-10-23T01:24:48.555565"
    }
  ]
}
```

## ğŸ”§ ì„¤ì • ì˜µì…˜

### í¬ë¡¤ëŸ¬ ì˜µì…˜

```python
scraper = WConceptScraper()

# URL ë³€ê²½ (ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬)
scraper.url = "https://display.wconcept.co.kr/rn/best?displayCategoryType=10102"

# ìµœëŒ€ ìƒí’ˆ ìˆ˜ ë³€ê²½
products = await scraper.scrape(max_products=100)
```

### ìŠ¤ì¼€ì¤„ëŸ¬ ì˜µì…˜

```python
# 30ë¶„ë§ˆë‹¤ ì‹¤í–‰
scheduler.add_job(scraping_job, 'interval', minutes=30)

# ë§¤ì¼ ì˜¤ì „ 9ì‹œ
scheduler.add_job(scraping_job, 'cron', hour=9, minute=0)

# ë§¤ì£¼ ì›”ìš”ì¼ ì˜¤ì „ 10ì‹œ
scheduler.add_job(scraping_job, 'cron', day_of_week='mon', hour=10)
```

## ğŸ“ˆ ë‹¤ìŒ ë‹¨ê³„

### Phase 1: ë°ì´í„°ë² ì´ìŠ¤ (ì¶”ì²œ)
- SQLite ë˜ëŠ” PostgreSQL ì„¤ì •
- ì‹œê³„ì—´ ë°ì´í„° ì €ì¥
- ì¸ë±ì‹± ìµœì í™”

### Phase 2: API ì„œë²„
- FastAPI ë°±ì—”ë“œ êµ¬ì¶•
- REST API ì—”ë“œí¬ì¸íŠ¸ ì œê³µ
- ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒ

### Phase 3: ì›¹ ëŒ€ì‹œë³´ë“œ
- React í”„ë¡ íŠ¸ì—”ë“œ
- ì°¨íŠ¸ ë° ì‹œê°í™”
- ì‹¤ì‹œê°„ ì•Œë¦¼

### Phase 4: ê³ ê¸‰ ê¸°ëŠ¥
- ë¨¸ì‹ ëŸ¬ë‹ íŠ¸ë Œë“œ ì˜ˆì¸¡
- ì´ë©”ì¼/í…”ë ˆê·¸ë¨ ì•Œë¦¼
- ì—‘ì…€ ë¦¬í¬íŠ¸ ìë™ ìƒì„±

## ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ: í¬ë¡¤ë§ ì‹¤íŒ¨
```bash
# ë¸Œë¼ìš°ì € ì¬ì„¤ì¹˜
playwright install chromium --force

# ê¶Œí•œ í™•ì¸
chmod +x wconcept_scraper_v2.py
```

### ë¬¸ì œ: íƒ€ì„ì•„ì›ƒ ì—ëŸ¬
```python
# timeout ê°’ ì¦ê°€
await page.goto(url, wait_until='domcontentloaded', timeout=60000)
```

### ë¬¸ì œ: ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ
```bash
# í˜ì´ì§€ ì†ŒìŠ¤ í™•ì¸
python -c "
import asyncio
from playwright.async_api import async_playwright

async def check():
    async with async_playwright() as p:
        browser = await p.chromium.launch()
        page = await browser.new_page()
        await page.goto('https://display.wconcept.co.kr/rn/best?displayCategoryType=10101&displaySubCategoryType=10101201&gnbType=Y')
        await page.wait_for_timeout(5000)
        print(await page.content())
        await browser.close()

asyncio.run(check())
"
```

## ğŸ“š ë¬¸ì„œ

- [FINAL_REPORT.md](./FINAL_REPORT.md) - ì „ì²´ ê²€ì¦ ë³´ê³ ì„œ
- [IMPLEMENTATION_GUIDE.md](./IMPLEMENTATION_GUIDE.md) - êµ¬í˜„ ê°€ì´ë“œ
- [feasibility_report.md](./feasibility_report.md) - ê¸°ìˆ  ë¶„ì„ ë³´ê³ ì„œ

## âš ï¸ ì£¼ì˜ì‚¬í•­

### ë²•ì /ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­
- Wì»¨ì…‰ì˜ `robots.txt` ì •ì±… ì¤€ìˆ˜
- ì ì ˆí•œ ìš”ì²­ ë¹ˆë„ ìœ ì§€ (ìµœì†Œ 30ë¶„ ê°„ê²© ê¶Œì¥)
- ê°œì¸ì •ë³´ ìˆ˜ì§‘ ê¸ˆì§€
- ìƒì—…ì  ì‚¬ìš© ì‹œ Wì»¨ì…‰ì˜ í—ˆê°€ í•„ìš”

### ê¸°ìˆ ì  ê³ ë ¤ì‚¬í•­
- ë„¤íŠ¸ì›Œí¬ ìƒíƒœì— ë”°ë¼ íƒ€ì„ì•„ì›ƒ ë°œìƒ ê°€ëŠ¥
- í˜ì´ì§€ êµ¬ì¡° ë³€ê²½ ì‹œ í¬ë¡¤ëŸ¬ ì—…ë°ì´íŠ¸ í•„ìš”
- ì¥ê¸° ì‹¤í–‰ ì‹œ ë©”ëª¨ë¦¬ ê´€ë¦¬ í•„ìš”

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

ì´ í”„ë¡œì íŠ¸ëŠ” ê°œì¸ í”„ë¡œì íŠ¸ì´ì§€ë§Œ, ê°œì„  ì œì•ˆì€ ì–¸ì œë‚˜ í™˜ì˜í•©ë‹ˆë‹¤.

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” êµìœ¡ ë° ì—°êµ¬ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.

## ğŸ’¬ ë¬¸ì˜

ë¬¸ì œê°€ ìˆê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.

---

## ğŸ‰ ì‹œì‘í•´ë³´ì„¸ìš”!

```bash
# 1. í¬ë¡¤ëŸ¬ ì‹¤í–‰
python wconcept_scraper_v2.py

# 2. ê²°ê³¼ í™•ì¸
cat wconcept_data_*.json | python -m json.tool | head -50

# 3. ë‹¤ìŒ ë‹¨ê³„ ì„ íƒ
# A. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
# B. API ì„œë²„ êµ¬ì¶•
# C. ì›¹ ëŒ€ì‹œë³´ë“œ ê°œë°œ
# D. ìë™í™” ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
```

**ëª¨ë“  ê¸°ëŠ¥ì´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì›í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì‹œìŠ¤í…œì„ í™•ì¥í•˜ì„¸ìš”!** ğŸš€
